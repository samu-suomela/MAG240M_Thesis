{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "For the GCN, we need to create an adjacency matrix of the graph. As the size of the graph is massive (1.2 million paper nodes), we need to use a sparse matrix due to its efficiency. It is also a requirement for training the model.\n",
    "\n",
    "First, let's practice with just the citation graph.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = np.load(\"test_data/author_array_test.npy\")\n",
    "papers = np.load(\"test_data/paper_array_test.npy\")\n",
    "paper_to_paper = np.load(\"test_data/edgelist_cites_test.npy\")\n",
    "author_to_paper = np.load(\"test_data/edgelist_writes_test.npy\")\n",
    "\n",
    "# Use this to fix the difference\n",
    "#np.setdiff1d(papers, np.unique(paper_to_paper))\n"
   ]
  },
  {
   "source": [
    "ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "    \n",
    "ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "\n",
    "ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "\n",
    "ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edgelist_reindexed = []\n",
    "papers_reindexed = []\n",
    "mapping = {}\n",
    "for i in range(len(papers)):\n",
    "    mapping[papers[i]] = i\n",
    "    papers_reindexed.append(i)\n",
    "\n",
    "for i in range(len(paper_to_paper.T)):\n",
    "    edge = paper_to_paper[:,i]\n",
    "    edgelist_reindexed.append([mapping[edge[0]],mapping[edge[1]]])\n",
    "\n",
    "paper_to_paper_reindexed = np.array(edgelist_reindexed).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = np.load(\"test_data/paper_label_test.npy\") # 153 classes in the data\n",
    "train_index = []\n",
    "test_index = []\n",
    "j = 0\n",
    "label_matrix = np.zeros((len(labels),153))\n",
    "for i in range(len(labels)):\n",
    "    if not np.isnan(labels[i]):\n",
    "        label_matrix[i,int(labels[i])] = 1\n",
    "        if j < 30:\n",
    "            train_index.append(i)\n",
    "            j += 1\n",
    "        else:\n",
    "            test_index.append(i)\n",
    "\n",
    "train_labels = label_matrix[train_index,:]\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.y', 'wb') as handle:\n",
    "    pickle.dump(train_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "test_labels = label_matrix[test_index,:]\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.ty', 'wb') as handle:\n",
    "    pickle.dump(test_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "label_matrix_no_test = np.delete(label_matrix, test_index, axis=0) # remove test index\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.ally', 'wb') as handle:\n",
    "    pickle.dump(label_matrix_no_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.test.index', 'w') as f:\n",
    "    for index in test_index:\n",
    "        f.write(str(index) + \"\\n\")\n"
   ]
  },
  {
   "source": [
    "ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "\n",
    "ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "\n",
    "ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
    "        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.load(\"test_data/feats_array_test.npy\")\n",
    "feature_matrix_no_test = np.delete(feature_matrix, test_index, axis=0) # remove test index\n",
    "feature_matrix_train = feature_matrix[train_index]\n",
    "feature_matrix_test = feature_matrix[test_index]\n",
    "\n",
    "sparse_feature_matrix = csr_matrix(feature_matrix_no_test)\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.allx', 'wb') as handle:\n",
    "    pickle.dump(sparse_feature_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "sparse_feature_matrix_train = csr_matrix(feature_matrix_train)\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.x', 'wb') as handle:\n",
    "    pickle.dump(sparse_feature_matrix_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "sparse_feature_matrix_test = csr_matrix(feature_matrix_test)\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.tx', 'wb') as handle:\n",
    "    pickle.dump(sparse_feature_matrix_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "source": [
    "ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict object;"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = dict()\n",
    "for edge in paper_to_paper_reindexed.T:\n",
    "    if edge[0] in G:\n",
    "        G[edge[0]].append(int(edge[1]))\n",
    "    else:\n",
    "        G[edge[0]] = [int(edge[1])]\n",
    "\n",
    "    if edge[1] in G: \n",
    "        G[edge[1]].append(int(edge[0]))\n",
    "    else:\n",
    "        G[edge[1]] = [int(edge[0])]\n",
    "\n",
    "for no_edge in np.setdiff1d(papers_reindexed, np.unique(paper_to_paper_reindexed)):\n",
    "    G[no_edge] = [int(no_edge)]\n",
    "\n",
    "with open('/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.graph', 'wb') as handle:\n",
    "    pickle.dump(G, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(180226, 768)\n(180226, 153)\n180241\n14\n(15, 768)\n(15, 153)\n(30, 768)\n(30, 153)\n"
     ]
    }
   ],
   "source": [
    "allx = pd.read_pickle(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.allx')\n",
    "ally = pd.read_pickle(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.ally')\n",
    "graph = pd.read_pickle(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.graph')\n",
    "index = pd.read_csv(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.test.index')\n",
    "tx = pd.read_pickle(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.tx')\n",
    "ty = pd.read_pickle(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.ty')\n",
    "x = pd.read_pickle(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.x')\n",
    "y = pd.read_pickle(r'/Users/Samu/Desktop/Koulu/Gradu/gcn/gcn/data/ind.mag_prac.y')\n",
    "\n",
    "print(allx.shape)\n",
    "print(ally.shape)\n",
    "print(len(graph))\n",
    "print(len(index))\n",
    "print(tx.shape)\n",
    "print(ty.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  }
 ]
}