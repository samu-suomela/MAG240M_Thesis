{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from ogb.lsc import MAG240MDataset\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset = MAG240MDataset(root = \"/Volumes/Seagate Backup Plus Drive/Gradu/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "'''\n",
    "edge_index is numpy.ndarray of shape (2, num_edges).\n",
    "- first row: indices of source nodes (indexed by source node types)\n",
    "- second row: indices of target nodes (indexed by target node types)\n",
    "In other words, i-th edge connects from edge_index[0,i] to edge_index[1,i].\n",
    "'''\n",
    "\n",
    "edge_index_cites = dataset.edge_index('paper', 'paper')\n",
    "edge_index_writes = dataset.edge_index('author', 'paper')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To create the test dataset to run on a regular computer, we begin by selecting an author and retrieving the papers they have contributed in. Next, we get the indexes of those papers, and retrieve both their citations and their authors. This cycle can be continued, and in the end we have an array of authors from which we can retrieve their affiliations. Then, we have an array of authors, an array of papers, three edgelists containing citations, writes and affiliations. We can then retrieve the required paper features from the array of papers and write the result into a file. \n",
    "\n",
    "We also need to select an article that actually has a label, since there are many unlabeled articles in the raw data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(np.where(dataset.paper_label==1))\n",
    "print(edge_index_writes[:,edge_index_writes[1]==85]) # retrieve the author of paper 85 and use that as a starting point"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(array([       85,      9052,      9166, ..., 121422531, 121494455,\n",
      "       121634237]),)\n",
      "[[1080565 1794309 7130696 7130697]\n",
      " [     85      85      85      85]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "paper_array = edge_index_writes[1,edge_index_writes[0]==1080565]\n",
    "mask_cites = np.in1d(edge_index_cites[0],paper_array)\n",
    "cites_array = edge_index_cites[:,mask_cites]\n",
    "\n",
    "n = 1\n",
    "\n",
    "for i in range(n):\n",
    "    paper_array = np.concatenate((paper_array, np.unique(cites_array[1])))\n",
    "    mask_cites = np.in1d(edge_index_cites[0],paper_array)\n",
    "    cites_array = edge_index_cites[:,mask_cites]\n",
    "\n",
    "mask_cites = np.in1d(edge_index_cites[0],paper_array)\n",
    "cites_array = edge_index_cites[:,mask_cites]\n",
    "paper_array = np.concatenate((paper_array, np.unique(cites_array[1])))\n",
    "print(paper_array)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[       84        85    490533 ... 121707152 121712380 121748774]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "paper_array_test = np.unique(paper_array)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "edgelist_cites_test = cites_array\n",
    "edgelist_cites_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[       84,        84,        84, ..., 121156360, 121156360,\n",
       "        121156360],\n",
       "       [  2576935,  61873589,  90818614, ..., 102342995, 109155579,\n",
       "        116684521]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "paper_label_test = dataset.paper_label[paper_array_test]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(paper_array_test.shape)\n",
    "print(edgelist_cites_test.shape)\n",
    "print(paper_label_test.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(11530,)\n",
      "(2, 14021)\n",
      "(11530,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "np.save('test_data_label_propagation/paper_array_test_label_propagation', paper_array_test)\n",
    "np.save('test_data_label_propagation/edgelist_cites_test_label_propagation', edgelist_cites_test)\n",
    "np.save('test_data_label_propagation/paper_label_test_label_propagation', paper_label_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we have a smaller part of MAG-dataset that should be much easier to train with, before attempting anything with the dataset as a whole. "
   ],
   "metadata": {}
  }
 ]
}